# 인공신경망 
1. 가중치와 편향
2. 활성화험수

### 1. 가중치와 편향
- 가중치 :  입력 데이터에서 원하는 연산 결과를 만들도록 비중을 부여하는 값
- 편향 : 뉴런의 활성화를 조절하는 상수
- 학습 : 실제 정답에 근사한 출력값을 만들기 위해 뉴런의 가중치와 편향을 반복적으로 조정하는 것

### 2. 활성화 함수
1. 시그모이드
2. 하이퍼볼릭 탄젠트
3. 렐루
4. 리키렐루
5. 🥇소프트맥스
- 시그모이드 
    - 입력값을 비선형 형태로 0~1 값으로 변환시킴
    - 입력이 너무 작거나 커지면 기울기(미분값)가 0에 수렴 
    - 미분값이 작은 시그모이드 함수를 은닉층의 활성화 함수로 사용하면 기울기 소실 문제가 발생해 모델 학습이 제대로 이루어지지 않음
    - <img width="135" height="56" alt="image" src="https://github.com/user-attachments/assets/08cf2dd2-c625-4853-bcd0-68174b310635" />

- 하이퍼볼릭 탄젠트
    - 시그모이드의 은닉층이 많아질수록 효과적으로 학습되지 않는 한계점을 개선하기 위한 방법
    - 출력 -1~1
    - 미분값이 시그모이드 함수에 비해 커짐 
    - x값이 크거나 작아짐에 따라 기울기가 매우 작아져서 기울기 소실 문제 발생
    - <img width="158" height="55" alt="image" src="https://github.com/user-attachments/assets/f5da0ba9-25d4-4838-8b55-71c504832ed1" />

- 렐루
    - 시그모이드와 하이퍼볼릭 기울기 소실 문제 해결 위한 함수
    - 입력이 양수일 경우 출력값은 입력값과 같음, 음수일 경우 출력값은 0
    - 입력이 음수인 뉴런의 출력을 회생시키지 못하는 한계 존재
    - <img width="137" height="31" alt="image" src="https://github.com/user-attachments/assets/b7412129-f9b4-4768-b672-9c005d5039fa" />

- 리키 렐루
    - 입력값이 음수일 때 출력값을 0이 아닌 0.001과 같은 매우 작은 값을 출력함
    - <img width="296" height="64" alt="image" src="https://github.com/user-attachments/assets/fe843c86-d74c-4c2e-bf8f-ff8eb645621d" />

- 소프트맥스
    - <u>다중 분류 모델</u>에 사용하는 활성화 함수
    - 입력값을 0~1사이 값으로 정규화 하여 출력
    - 출력값들의 총합은 1
    - 분류할 클래스가 n개일 때, 출력값은 n개(입력이 각 클래스에 속할 확률 추정치임)
    - 용도 : 이미지 인식(고양이, 개, 새 중 하나), 뉴스 기사 분류(정치, 경제, 스포츠 중 하나) 등
    - <img width="117" height="56" alt="image" src="https://github.com/user-attachments/assets/93aa60ae-404e-414b-b037-0c712c3bbeb2" />

